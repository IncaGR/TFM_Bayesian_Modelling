vector[N] y;
real x1[N];
int x2[N];
int x3[N];
int x4[N];
int x5[N];
int x6[N];
int x7[N];
int x8[N];
int x9[N];
int x10[N];
int x11[N];
int x12[N];
int barri[N];
vector[J] mean_income;
}
parameters {
real b0[J];
real log_smt; // log square mt
real rooms2_1 ; // rooms
real rooms2_2; // rooms
real rooms2_3; // rooms
real rooms2_4; // rooms
real asc; // asc
real wc2_2; // wc
real wc2_3; // wc
real wc2_4; // wc
real terraza;
real amueblado;
real lujo;
real g_0;
real g_1;
real<lower=0> sigma_y;
real<lower=0> sigma_a;
}
model {
sigma_y ~ cauchy(0, 10);
sigma_a ~ cauchy(0, 10);
g_0 ~ cauchy(0,10);
g_1 ~cauchy(0,10);
log_smt ~ cauchy(0,2.5);
rooms2_1 ~ cauchy(0,2.5);
rooms2_2 ~ cauchy(0,2.5);
rooms2_3 ~ cauchy(0,2.5);
rooms2_4 ~ cauchy(0,2.5);
asc ~ cauchy(0,2.5);
wc2_2 ~ cauchy(0,2.5);
wc2_3 ~ cauchy(0,2.5);
wc2_4 ~ cauchy(0,2.5);
terraza ~ cauchy(0,2.5);
amueblado ~ cauchy(0,2.5);
lujo ~ cauchy(0,2.5);
for (j in 1:J)
b0[j] ~ normal(g_0 + g_1 * mean_income[j], sigma_a);
for (n in 1:N)
y[n] ~ normal(b0[barri[n]] + log_smt * x1[n] + rooms2_1 * x2[n] +
rooms2_2 * x3[n] + rooms2_3 * x4[n] + rooms2_4 * x5[n] +
asc * x6[n] + wc2_2 * x7[n] + wc2_3 * x8[n] + wc2_4 * x9[n] +
terraza * x10[n] + amueblado * x11[n] + lujo * x12[n], sigma_y);
}
"
translate = stanc(model_code  = model_code)
model = stan_model(stanc_ret = translate)
# Fit the model to the data
fit_4 <- sampling(model, data = data_list, chains = 4, iter =6000, verbose = TRUE, seed = 132) # 4000?
# path_to_save = paste0("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_priors.RDS") # with priors
# path_to_save = paste0("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_1.RDS") # wc cov
# path_to_save = paste0("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_2.RDS") # terrace
# path_to_save = paste0("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_2_1.RDS") # lujo cauchy narrow
# path_to_save = paste0("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_3.RDS") # asc
# path_to_save = paste0("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_4.RDS") # terraza
# path_to_save = paste0("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_5.RDS") # playa
# path_to_save = paste0("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_6.RDS") # intercept: playa+renta
# path_to_save = paste0("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_7.RDS") # varying the slope # no converge
# path_to_save = paste0("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_8.RDS") # no lujo data
path_to_save = paste0("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_9.RDS") # all variables
saveRDS(fit_4, path_to_save)
# ## Convergence analysis
print(fit_4) # Cuando hay porblemas de multicolinearidad max depth sube y r-hat
#   f ~ cauchy(0,2.5);
#   b6 ~ cauchy(0,2.5);
#   for (j in 1:J)
#     a[j] ~ normal(g_0 + g_1 * mean_income[j], sigma_a);
#   for (n in 1:N)
#     y[n] ~ normal(a[barri[n]] + b * x1[n] + c * x2[n] + d * x3[n]
#     //+ e * x4[n]
#      + f * x5[n] + b6 * terraza[n] , sigma_y);
# }
# "
model_code <- "
data {
int<lower=0> N;
int<lower=0> J;
vector[N] y;
real x1[N];
int x2[N];
int x3[N];
int x4[N];
int x5[N];
int x6[N];
int x7[N];
int x8[N];
int x9[N];
int x10[N];
int x11[N];
int x12[N];
int barri[N];
vector[J] mean_income;
}
parameters {
real b0[J];
real log_smt; // log square mt
real rooms2_1 ; // rooms
real rooms2_2; // rooms
real rooms2_3; // rooms
real rooms2_4; // rooms
real asc; // asc
real wc2_2; // wc
real wc2_3; // wc
real wc2_4; // wc
real terraza;
real amueblado;
real lujo;
real g_0;
real g_1;
real<lower=0> sigma_y;
real<lower=0> sigma_a;
}
model {
sigma_y ~ cauchy(0, 10);
sigma_a ~ cauchy(0, 10);
// g_0 ~ cauchy(0,10);
// g_1 ~cauchy(0,10);
log_smt ~ cauchy(0,2.5);
rooms2_1 ~ cauchy(0,2.5);
rooms2_2 ~ cauchy(0,2.5);
rooms2_3 ~ cauchy(0,2.5);
rooms2_4 ~ cauchy(0,2.5);
asc ~ cauchy(0,2.5);
wc2_2 ~ cauchy(0,2.5);
wc2_3 ~ cauchy(0,2.5);
wc2_4 ~ cauchy(0,2.5);
terraza ~ cauchy(0,2.5);
amueblado ~ cauchy(0,2.5);
lujo ~ cauchy(0,2.5);
for (j in 1:J)
b0[j] ~ normal(g_0 + g_1 * mean_income[j], sigma_a);
for (n in 1:N)
y[n] ~ normal(b0[barri[n]] + log_smt * x1[n] + rooms2_1 * x2[n] +
rooms2_2 * x3[n] + rooms2_3 * x4[n] + rooms2_4 * x5[n] +
asc * x6[n] + wc2_2 * x7[n] + wc2_3 * x8[n] + wc2_4 * x9[n] +
terraza * x10[n] + amueblado * x11[n] + lujo * x12[n], sigma_y);
}
"
translate = stanc(model_code  = model_code)
model = stan_model(stanc_ret = translate)
# Fit the model to the data
fit_4 <- sampling(model, data = data_list, chains = 4, iter =5000, verbose = TRUE, seed = 132) # 4000?
library(tidyverse)
library(car)
library(here)
library(broom)
library(broom.mixed)
library(rstan)
library(bayesplot)
# upload data ready for modelling ------------------------------------------
options(mc.cores = parallel::detectCores())
rstan_options(auto_write=TRUE )
# install.packages("https://cran.r-project.org/src/contrib/Archive/StanHeaders/StanHeaders_2.21.0-7.tar.gz",
#                  type="source",repos=NULL)
packageVersion("StanHeaders")
packageVersion("rstan")
data_date = "2023-05-03"
path_modelling = paste0("data_lm_cook_",data_date,".RDS")
data_cook<- readRDS(here::here('Desktop','1_projects','TFM','1_data','2_data_Idealista',path_modelling))
data_cook$barri <- as.factor(data_cook$barri)
# no lujo?
data_cook = data_cook %>% filter(lujo == 0)
names(data_cook)
N= nrow(data_cook)
barri_name <- unique(data_cook$barri)
barri <- as.numeric(data_cook$barri)
J <- length(unique(barri))
y <- data_cook$log_price
x1 <- log(data_cook$square_mt)
x2 <- data_cook$rooms2_1
x3 <- data_cook$rooms2_2
x4 <- data_cook$rooms2_3
x5 <- data_cook$rooms2_4
x6 <- data_cook$asc
x7 <- data_cook$wc2_2
x8 <- data_cook$wc2_3
x9 <- data_cook$wc2_4
x10 <- data_cook$terraza
x11 <- data_cook$amueblado
x12 <- data_cook$lujo
mean_income <- data_cook %>%
group_by(barri) %>%
summarise(mean_income = first(log(mean_income))) %>%
pull(mean_income)
data_list <- list(
N = N,
y = y,
J = J,
x1 = x1,
x2 = x2,
x3 = x3,
x4 = x4,
x5 = x5,
x6 = x6,
x7 = x7,
x8 = x8,
x9 = x9,
x10 = x10,
x11 = x11,
x12 = x12,
barri = barri,
mean_income = mean_income
)
#   f ~ cauchy(0,2.5);
#   b6 ~ cauchy(0,2.5);
#   for (j in 1:J)
#     a[j] ~ normal(g_0 + g_1 * mean_income[j], sigma_a);
#   for (n in 1:N)
#     y[n] ~ normal(a[barri[n]] + b * x1[n] + c * x2[n] + d * x3[n]
#     //+ e * x4[n]
#      + f * x5[n] + b6 * terraza[n] , sigma_y);
# }
# "
model_code <- "
data {
int<lower=0> N;
int<lower=0> J;
vector[N] y;
real x1[N];
int x2[N];
int x3[N];
int x4[N];
int x5[N];
int x6[N];
int x7[N];
int x8[N];
int x9[N];
int x10[N];
int x11[N];
int x12[N];
int barri[N];
vector[J] mean_income;
}
parameters {
real b0[J];
real log_smt; // log square mt
real rooms2_1 ; // rooms
real rooms2_2; // rooms
real rooms2_3; // rooms
real rooms2_4; // rooms
real asc; // asc
real wc2_2; // wc
real wc2_3; // wc
real wc2_4; // wc
real terraza;
real amueblado;
real lujo;
real g_0;
real g_1;
real<lower=0> sigma_y;
real<lower=0> sigma_a;
}
model {
sigma_y ~ cauchy(0, 10);
sigma_a ~ cauchy(0, 10);
// g_0 ~ cauchy(0,10);
// g_1 ~cauchy(0,10);
log_smt ~ cauchy(0,2.5);
rooms2_1 ~ cauchy(0,2.5);
rooms2_2 ~ cauchy(0,2.5);
rooms2_3 ~ cauchy(0,2.5);
rooms2_4 ~ cauchy(0,2.5);
asc ~ cauchy(0,2.5);
wc2_2 ~ cauchy(0,2.5);
wc2_3 ~ cauchy(0,2.5);
wc2_4 ~ cauchy(0,2.5);
terraza ~ cauchy(0,2.5);
amueblado ~ cauchy(0,2.5);
lujo ~ cauchy(0,2.5);
for (j in 1:J)
b0[j] ~ normal(g_0 + g_1 * mean_income[j], sigma_a);
for (n in 1:N)
y[n] ~ normal(b0[barri[n]] + log_smt * x1[n] + rooms2_1 * x2[n] +
rooms2_2 * x3[n] + rooms2_3 * x4[n] + rooms2_4 * x5[n] +
asc * x6[n] + wc2_2 * x7[n] + wc2_3 * x8[n] + wc2_4 * x9[n] +
terraza * x10[n] + amueblado * x11[n] + lujo * x12[n], sigma_y);
}
"
translate = stanc(model_code  = model_code)
model = stan_model(stanc_ret = translate)
# Fit the model to the data
fit_4 <- sampling(model, data = data_list, chains = 4, iter =5000, verbose = TRUE, seed = 132) # 4000?
# path_to_save = paste0("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_priors.RDS") # with priors
# path_to_save = paste0("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_1.RDS") # wc cov
# path_to_save = paste0("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_2.RDS") # terrace
# path_to_save = paste0("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_2_1.RDS") # lujo cauchy narrow
# path_to_save = paste0("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_3.RDS") # asc
# path_to_save = paste0("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_4.RDS") # terraza
# path_to_save = paste0("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_5.RDS") # playa
# path_to_save = paste0("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_6.RDS") # intercept: playa+renta
# path_to_save = paste0("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_7.RDS") # varying the slope # no converge
# path_to_save = paste0("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_8.RDS") # no lujo data
path_to_save = paste0("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_9.RDS") # all variables
saveRDS(fit_4, path_to_save)
# ## Convergence analysis
print(fit_4) # Cuando hay porblemas de multicolinearidad max depth sube y r-hat
setwd("C:/Users/ggari/Desktop/1_projects/TFM")
library(tidyverse)
library(car)
library(here)
library(broom)
library(broom.mixed)
library(rstan)
library(bayesplot)
# upload data ready for modelling ------------------------------------------
options(mc.cores = parallel::detectCores())
rstan_options(auto_write=TRUE )
# install.packages("https://cran.r-project.org/src/contrib/Archive/StanHeaders/StanHeaders_2.21.0-7.tar.gz",
#                  type="source",repos=NULL)
packageVersion("StanHeaders")
packageVersion("rstan")
data_date = "2023-05-03"
path_modelling = paste0("data_lm_cook_",data_date,".RDS")
data_cook<- readRDS(here::here('1_data','2_data_Idealista',path_modelling))
data_cook$barri <- as.factor(data_cook$barri)
# no lujo?
data_cook = data_cook %>% filter(lujo == 0)
data_cook<- readRDS(here::here('1_data','2_data_Idealista',path_modelling))
data_cook$barri <- as.factor(data_cook$barri)
names(data_cook)
unique(data_cook$lujo)
names(data_cook)
N= nrow(data_cook)
barri_name <- unique(data_cook$barri)
barri <- as.numeric(data_cook$barri)
J <- length(unique(barri))
y <- data_cook$log_price
x1 <- log(data_cook$square_mt)
x2 <- data_cook$rooms2_1
x3 <- data_cook$rooms2_2
x4 <- data_cook$rooms2_3
x5 <- data_cook$rooms2_4
x6 <- data_cook$asc
x7 <- data_cook$wc2_2
x8 <- data_cook$wc2_3
x9 <- data_cook$wc2_4
x10 <- data_cook$terraza
x11 <- data_cook$amueblado
x12 <- data_cook$lujo
mean_income <- data_cook %>%
group_by(barri) %>%
summarise(mean_income = first(log(mean_income))) %>%
pull(mean_income)
data_list <- list(
N = N,
y = y,
J = J,
x1 = x1,
x2 = x2,
x3 = x3,
x4 = x4,
x5 = x5,
x6 = x6,
x7 = x7,
x8 = x8,
x9 = x9,
x10 = x10,
x11 = x11,
x12 = x12,
barri = barri,
mean_income = mean_income
)
#   f ~ cauchy(0,2.5);
#   b6 ~ cauchy(0,2.5);
#   for (j in 1:J)
#     a[j] ~ normal(g_0 + g_1 * mean_income[j], sigma_a);
#   for (n in 1:N)
#     y[n] ~ normal(a[barri[n]] + b * x1[n] + c * x2[n] + d * x3[n]
#     //+ e * x4[n]
#      + f * x5[n] + b6 * terraza[n] , sigma_y);
# }
# "
model_code <- "
data {
int<lower=0> N;
int<lower=0> J;
vector[N] y;
real x1[N];
int x2[N];
int x3[N];
int x4[N];
int x5[N];
int x6[N];
int x7[N];
int x8[N];
int x9[N];
int x10[N];
int x11[N];
int x12[N];
int barri[N];
vector[J] mean_income;
}
parameters {
real b0[J];
real log_smt; // log square mt
real rooms2_1 ; // rooms
real rooms2_2; // rooms
real rooms2_3; // rooms
real rooms2_4; // rooms
real asc; // asc
real wc2_2; // wc
real wc2_3; // wc
real wc2_4; // wc
real terraza;
real amueblado;
real lujo;
real g_0;
real g_1;
real<lower=0> sigma_y;
real<lower=0> sigma_a;
}
model {
sigma_y ~ cauchy(0, 10);
sigma_a ~ cauchy(0, 10);
// g_0 ~ cauchy(0,10);
// g_1 ~cauchy(0,10);
log_smt ~ cauchy(0,2.5);
rooms2_1 ~ cauchy(0,2.5);
rooms2_2 ~ cauchy(0,2.5);
rooms2_3 ~ cauchy(0,2.5);
rooms2_4 ~ cauchy(0,2.5);
asc ~ cauchy(0,2.5);
wc2_2 ~ cauchy(0,2.5);
wc2_3 ~ cauchy(0,2.5);
wc2_4 ~ cauchy(0,2.5);
terraza ~ cauchy(0,2.5);
amueblado ~ cauchy(0,2.5);
lujo ~ cauchy(0,2.5);
for (j in 1:J)
b0[j] ~ normal(g_0 + g_1 * mean_income[j], sigma_a);
for (n in 1:N)
y[n] ~ normal(b0[barri[n]] + log_smt * x1[n] + rooms2_1 * x2[n] +
rooms2_2 * x3[n] + rooms2_3 * x4[n] + rooms2_4 * x5[n] +
asc * x6[n] + wc2_2 * x7[n] + wc2_3 * x8[n] + wc2_4 * x9[n] +
terraza * x10[n] + amueblado * x11[n] + lujo * x12[n], sigma_y);
}
"
translate = stanc(model_code  = model_code)
model = stan_model(stanc_ret = translate)
table(data_cook$lujo)
fit_4 <- sampling(model, data = data_list, chains = 4, iter =5000, verbose = TRUE, seed = 132) # 4000?
path_to_save = paste0("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_9.RDS") # all variables # checkeo
# si lujo estaba en el dataset...
saveRDS(fit_4, path_to_save)
# ## Convergence analysis
print(fit_4) # Cuando hay porblemas de multicolinearidad max depth sube y r-hat
### Test model
# We are going to test our hierarchical model with the next month data.
library(dplyr)
library(ggplot2)
library(rstan)
library(here)
library(broom.mixed)
data_date = "2023-06-05"
path_modelling = paste0("data_lm_cook_",data_date,".RDS")
test_data<- readRDS(here::here('1_data','2_data_Idealista',path_modelling))
test_data$barri <- as.factor(test_data$barri)
table(test_data$barri)
test_data = test_data[!is.na(test_data$price),]
summary(test_data)
y <- exp(test_data$log_price)
fit <- readRDS("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_9.RDS")
fit
# Extract the parameter samples from the fitted model
sims <- rstan::extract(fit)
# Generate predictions for the test data
n.sims <- nrow(sims$b0)
n.test <- nrow(test_data)
y.tilde <- matrix(0, nrow = n.sims, ncol = n.test)
for (i in 1:n.test) {
print(i)
y.tilde[,i] <- rnorm(n.sims, sims$b0[,test_data$barri[i]] + sims$log_smt * log(test_data$square_mt[i])
+ sims$rooms2_1 * test_data$rooms2_1[i]
+ sims$rooms2_2 * test_data$rooms2_2[i]
+ sims$rooms2_3 * test_data$rooms2_3[i]
+ sims$rooms2_4 * test_data$rooms2_4[i]
+ sims$wc2_2 * test_data$wc2_2[i]
+ sims$wc2_3 * test_data$wc2_3[i]
+ sims$wc2_4 * test_data$wc2_4[i]
+ sims$asc * test_data$asc[i]
+ sims$terraza * test_data$terraza[i]
+ sims$amueblado * test_data$amueblado[i]
+ sims$lujo * test_data$lujo[i]
, sims$sigma_y)
}
# # Transform the predictions back to the original scale
y.tilde.exp <- exp(y.tilde)
# Compute the predicted mean price for each observation in the test datahttp://127.0.0.1:36221/graphics/plot_zoom_png?width=2195&height=1182
predicted_means <- apply(y.tilde.exp, 2, mean)
# Compute the actual mean price for each observation in the test data
actual_means <- exp(test_data$log_price)
# Compute a measure of predictive performance
RMSE <- sqrt(mean((predicted_means - actual_means)^2))
print(RMSE)
rsquared = 1 - (sum((actual_means - predicted_means)^2)/sum((actual_means - mean(actual_means))^2))
print(rsquared)

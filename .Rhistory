pull(mean_income)
data_list <- list(
N = N,
J = J,
y = y,
x1 = x1, # log square mt
x2 = x2, # nº rooms
x3 = x3, # nº wc
x4 = x4, # lujo
x5 = x5,
terraza = terraza,
# playa = playa,
barri = barri,
mean_income = mean_income
# ,mean_atur = mean_atur
)
data_list <- list(
N = N,
J = J,
y = y,
x1 = x1, # log square mt
x2 = x2, # nº rooms
x3 = x3, # nº wc
# x4 = x4, # lujo
x5 = x5,
terraza = terraza,
# playa = playa,
barri = barri,
mean_income = mean_income
# ,mean_atur = mean_atur
)
model_code <- "
data {
int<lower=0> N;
int<lower=0> J;
vector[N] y; // log price
real x1[N]; // log square mt
int x2[N]; // nº rooms
int x3[N]; // nº wc
// int x4[N]; // binari lujo
int x5[N]; // binari elevator
int terraza[N];
int barri[N];
// int playa[J]; no effect
vector[J] mean_income;
//vector[J] mean_atur; no effect
}
parameters {
real a[J]; // intercept each barri
real<lower=0> b; // log square mt
real c; // nº rooms
real<lower=0> d; // numeric nº wc
//real<lower=0> e; // lujo
real<lower=0> f; // asc
real<lower=0> b6; // terraza
real g_0;
real g_1;
// real g_2; no effect
//real g_3; no effect
real<lower=0> sigma_y;
real<lower=0> sigma_a;
}
model {
sigma_y ~ cauchy(0, 10);
sigma_a ~ cauchy(0, 10);
b ~ cauchy(0,2.5);
c ~ cauchy(0,2.5);
d ~ cauchy(0,2.5);
//e ~ cauchy(0,2.5);
f ~ cauchy(0,2.5);
b6 ~ cauchy(0,2.5);
for (j in 1:J)
a[j] ~ normal(g_0 + g_1 * mean_income[j], sigma_a);
for (n in 1:N)
y[n] ~ normal(a[barri[n]] + b * x1[n] + c * x2[n] + d * x3[n]
//+ e * x4[n]
+ f * x5[n] + b6 * terraza[n] , sigma_y);
}
"
translate = stanc(model_code  = model_code)
model = stan_model(stanc_ret = translate)
data_cook %>% filter(lujo == 0)
# no lujo?
data_cook = data_cook %>% filter(lujo == 0)
names(data_cook)
# no lujo?
data_cook = data_cook %>% filter(lujo == 0)
names(data_cook)
N= nrow(data_cook)
barri_name <- unique(data_cook$barri)
barri <- as.integer((data_cook$barri))
J <- length(unique(barri))
y <- data_cook$log_price
x1 <- log(data_cook$square_mt)
# x1 <- data_cook$square_mt # test no log NO USE TAKE MUCH TIME
x2 <- data_cook$rooms
# x2 <- data_cook$rooms2 # test no working only numeric vals
x3 <- data_cook$wc # test other wc2, wcx
# x4 <- data_cook$lujo
x5 <- data_cook$asc
terraza <- data_cook$terraza
# playa <- data_cook$barri_playa
mean_income <- data_cook %>%
group_by(barri) %>%
summarise(mean_income = first(log(mean_income))) %>%
pull(mean_income)
data_list <- list(
N = N,
J = J,
y = y,
x1 = x1, # log square mt
x2 = x2, # nº rooms
x3 = x3, # nº wc
# x4 = x4, # lujo
x5 = x5,
terraza = terraza,
# playa = playa,
barri = barri,
mean_income = mean_income
# ,mean_atur = mean_atur
)
model_code <- "
data {
int<lower=0> N;
int<lower=0> J;
vector[N] y; // log price
real x1[N]; // log square mt
int x2[N]; // nº rooms
int x3[N]; // nº wc
// int x4[N]; // binari lujo
int x5[N]; // binari elevator
int terraza[N];
int barri[N];
// int playa[J]; no effect
vector[J] mean_income;
//vector[J] mean_atur; no effect
}
parameters {
real a[J]; // intercept each barri
real<lower=0> b; // log square mt
real c; // nº rooms
real<lower=0> d; // numeric nº wc
//real<lower=0> e; // lujo
real<lower=0> f; // asc
real<lower=0> b6; // terraza
real g_0;
real g_1;
// real g_2; no effect
//real g_3; no effect
real<lower=0> sigma_y;
real<lower=0> sigma_a;
}
model {
sigma_y ~ cauchy(0, 10);
sigma_a ~ cauchy(0, 10);
b ~ cauchy(0,2.5);
c ~ cauchy(0,2.5);
d ~ cauchy(0,2.5);
//e ~ cauchy(0,2.5);
f ~ cauchy(0,2.5);
b6 ~ cauchy(0,2.5);
for (j in 1:J)
a[j] ~ normal(g_0 + g_1 * mean_income[j], sigma_a);
for (n in 1:N)
y[n] ~ normal(a[barri[n]] + b * x1[n] + c * x2[n] + d * x3[n]
//+ e * x4[n]
+ f * x5[n] + b6 * terraza[n] , sigma_y);
}
"
translate = stanc(model_code  = model_code)
# Fit the model to the data
fit_4 <- sampling(model, data = data_list, chains = 4, iter =6000, verbose = TRUE, seed = 132) # 4000?
# ## Convergence analysis
print(fit_4) # Cuando hay porblemas de multicolinearidad max depth sube y r-hat
### Test model
# We are going to test our hierarchical model with the next month data.
library(dplyr)
library(ggplot2)
data_date = "2023-06-05"
path_modelling = paste0("data_lm_cook_",data_date,".RDS")
test_data<- readRDS(here::here('Desktop','1_projects','TFM','1_data','2_data_Idealista',path_modelling))
test_data$barri <- as.factor(test_data$barri)
table(test_data$barri)
test_data = test_data[!is.na(test_data$price),]
summary(test_data)
test_data = test_data %>% filter(lujo == 0)
# fit <- readRDS("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4.RDS") # this is better 842.1371
# fit <- readRDS("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_priors.RDS") # 842.204
# fit <- readRDS("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_1.RDS") # 800.5172
# fit <- readRDS("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_2.RDS") # 797.9225
# fit <- readRDS("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_2_1.RDS") # 798.4418
# fit <- readRDS("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_3.RDS") # no lujo 586.7039
# fit <- readRDS("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_4.RDS") # 581.281 # Best model
# fit <- readRDS("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_5.RDS")
# fit <- readRDS("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_6.RDS") # 1050.08, 0.700949
fit <- readRDS("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_8.RDS")
saveRDS(fit_4, path_to_save)
# ## Convergence analysis
print(fit_4) # Cuando hay porblemas de multicolinearidad max depth sube y r-hat
# path_to_save = paste0("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_no_log.RDS") # test no log square mt
# path_to_save = paste0("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_priors.RDS") # with priors
# path_to_save = paste0("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_1.RDS") # wc cov
# path_to_save = paste0("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_2.RDS") # terrace
# path_to_save = paste0("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_2_1.RDS") # lujo cauchy narrow
# path_to_save = paste0("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_3.RDS") # asc
# path_to_save = paste0("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_4.RDS") # terraza
# path_to_save = paste0("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_5.RDS") # playa
# path_to_save = paste0("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_6.RDS") # intercept: playa+renta
# path_to_save = paste0("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_7.RDS") # varying the slope # no converge
path_to_save = paste0("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_8.RDS") # no lujo data
saveRDS(fit_4, path_to_save)
# fit <- readRDS("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4.RDS") # this is better 842.1371
# fit <- readRDS("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_priors.RDS") # 842.204
# fit <- readRDS("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_1.RDS") # 800.5172
# fit <- readRDS("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_2.RDS") # 797.9225
# fit <- readRDS("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_2_1.RDS") # 798.4418
# fit <- readRDS("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_3.RDS") # no lujo 586.7039
# fit <- readRDS("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_4.RDS") # 581.281 # Best model
# fit <- readRDS("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_5.RDS")
# fit <- readRDS("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_6.RDS") # 1050.08, 0.700949
fit <- readRDS("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/3_fitted_data/model_4_8.RDS")
summary(fit)
# Extract the parameter samples from the fitted model
sims <- rstan::extract(fit)
# Generate predictions for the test data
n.sims <- nrow(sims$a)
n.test <- nrow(test_data)
y.tilde <- matrix(0, nrow = n.sims, ncol = n.test)
for (i in 1:n.test) {
y.tilde[,i] <- rnorm(n.sims, sims$a[,test_data$barri[i]] + sims$b * log(test_data$square_mt[i]) + sims$c * test_data$rooms[i]
+ sims$d * test_data$wc[i] +
# sims$e * test_data$lujo[i] +
sims$f * test_data$asc[i]
+ sims$b6 * test_data$terraza[i]
# + sims$b7 * test_data$barri_playa[i]
, sims$sigma_y)
}
# # Transform the predictions back to the original scale
y.tilde.exp <- exp(y.tilde)
# Compute the predicted mean price for each observation in the test datahttp://127.0.0.1:36221/graphics/plot_zoom_png?width=2195&height=1182
predicted_means <- apply(y.tilde.exp, 2, mean)
# Compute the actual mean price for each observation in the test data
actual_means <- exp(test_data$log_price)
# Compute a measure of predictive performance
RMSE <- sqrt(mean((predicted_means - actual_means)^2))
print(RMSE)
rsquared = 1 - (sum((actual_means - predicted_means)^2)/sum((actual_means - mean(actual_means))^2))
print(rsquared)
plot(actual_means,predicted_means)
test_data$y_tilde = predicted_means
names(test_data)
test_data %>% ggplot(aes(x=price,y=y_tilde,color = as.factor(lujo))) + geom_jitter(alpha=0.5,shape = 1) +
facet_wrap(vars(distrito2)) +
theme_bw()
print(RMSE)
library(rstanarm)
options(mc.cores = parallel::detectCores())
data_date = "2023-05-03"
path_modelling = paste0("data_lm_cook_",data_date,".RDS")
data_cook<- readRDS(here::here('Desktop','1_projects','TFM','1_data','2_data_Idealista',path_modelling))
data_cook$barri <- as.factor(data_cook$barri)
names(data_cook)
stan_lmer(log_price ~ log(square_mt) + (1))
stan_lmer(log_price ~ log(square_mt) + (1|barri), data = data_cook)
print.stanreg()
library(tidyverse)
library(car)
library(here)
library(broom)
library(broom.mixed)
# MODELLING DATE
data_date = "2023-05-03"
# PREDICT DATE
data_predict = "2023-06-05"
path_modelling = paste0("data_modelling_",data_date,".RDS")
data_idealista <- readRDS(here::here('Desktop','1_projects','TFM','1_data','2_data_Idealista',path_modelling))
data_idealista$rooms2 <- as.factor(data_idealista$rooms2)
unique(data_idealista$distrito2)
data_idealista = data_idealista %>% mutate(barri_playa = ifelse(barri %in% c("la Barceloneta",
"la Vila Olímpica del Poblenou",
"el Poblenou",
"Diagonal Mar i el Front Marítim del Poblenou",
"el Besòs i el Maresme"),1,0))
regressors<-c(
# "barri",
"distrito2",
"terraza",
# "balcon",
# "estado" ,
# "armarios",
# "cocina",
"amueblado",
# "planta",
# "calef",
"asc",
# "aire",
"exterior",
# "casa",
"estudio",
"wc2",
"rooms2",
# "rooms_ord",
# # "terraza_balcon",
# "n_hospitals_barri",
# # "n_hospitals_districte",
# "hospitals",
# "caps",
"cuaps",
"n_terrazas_barri",
# # "n_terrazas_districte",
# # "mean_cadires_b",
"mean_superficie_b",
"mean_taules_b",
# "n_arbres_bcn_barri",
# # "n_arbres_bcn_districte",
"n_arbres_viaris_barri",
# # "n_arbres_viaris_districte",
"n_bar_copas_barri",
# # "n_bar_copas_districte",
"square_mt",
"new_planta",
"flag_planta",
"mean_income",
"barri_playa"
)
lm0 <- lm(reformulate("square_mt","log_price"),
data_idealista)
lm0 <- lm(reformulate("square_mt + mean_income + barri_playa","log_price"),
data_idealista)
lm1 <- lm(reformulate("square_mt + rooms","log_price"),
data_idealista)
lm1 <- lm(reformulate("square_mt + rooms2","log_price"),
data_idealista)
lm2 <- lm(reformulate(regressors,"log_price"),
data_idealista)
lm3 <- lm(reformulate("square_mt + asc","log_price"),
data_idealista)
lm4 <- lm(reformulate("square_mt + asc + rooms2","log_price"),
data_idealista)
df_x = data_idealista
# df_x$new_planta = as.factor(df_x$new_planta)
df_x$new_planta = as.numeric(df_x$new_planta)
lm5 <- lm(reformulate("square_mt + asc + rooms2 + new_planta + flag_planta ","log_price"),
df_x)
lm6 <- lm(reformulate("square_mt + asc + rooms2 + new_planta + flag_planta + wc2 + barri_playa","log_price"),
df_x)
round((exp(coef(lm6))-1)*100,2)
plot(lm6,which = 3)
df_x$n_arbres_viaris_barri = as.factor(df_x$n_arbres_viaris_barri)
df_x = df_x %>% mutate(n_arbres_viaris_barri = ifelse(barri == "el Coll",0,n_arbres_viaris_barri))
lm7 <- lm(log_price ~ 1 + barri + square_mt + asc + rooms2 + new_planta +
flag_planta + wc2 + terraza + exterior + amueblado
+ lujo
, data = df_x)
# exterior negativo? ruido?
round((exp(coef(lm7))-1)*100,2)
summary(lm0)
summary(lm1)
summary(lm2)
summary(lm3)
summary(lm4)
summary(lm5)
summary(lm6)
summary(lm7)
lm7 <- lm(log_price ~ 1 + barri + log(square_mt) + asc + rooms2 + new_planta +
flag_planta + wc2 + terraza + exterior + amueblado
+ lujo
, data = df_x)
# exterior negativo? ruido?
round((exp(coef(lm7))-1)*100,2)
summary(lm7)
lm7 <- lm(log_price ~ 1 + barri + square_mt + asc + rooms2 + new_planta +
flag_planta + wc2 + terraza + exterior + amueblado
+ lujo
, data = df_x)
summary(lm7)
coefs <- tidy(lm7, conf.int = TRUE)
# Crea el gráfico utilizando ggplot2
ggplot(coefs, aes(x = term, y = estimate)) +
geom_point() +
geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(x = "Variables", y = "Estimación", title = "Coeficientes e Intervalos de Confianza del 95%")
# Identifica las variables que corresponden a los barrios
coefs$term_group <- ifelse(grepl("^barri", coefs$term), "barri", "other")
# Organiza los términos primero por el grupo (barri u other) y luego alfabéticamente
coefs <- coefs %>%
arrange(term_group, term)
# Elimina la columna term_group ya que ya no la necesitamos
coefs$term_group <- NULL
# Convierte la variable term en una variable categórica con el orden específico
coefs$term <- factor(coefs$term, levels = coefs$term)
# Crea el gráfico
ggplot(coefs, aes(x = term, y = estimate)) +
geom_point() +
geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(x = "Variables", y = "Estimación", title = "Coeficientes e Intervalos de Confianza del 95%")
vif(lm7)
plot(lm7,ask=F)
# sort(cooks.distance(lm1))
cooksd =  cooks.distance(lm7)
df_x$cookd = cooks.distance(lm7)
names(df_x)
df_x = df_x %>% select(-c(X,area,id,name,zone,ubicacion_full,calle,barrio,barrio2,distrito,price_before,estado,año,datalles2,
cp,actualizacion,actualizacion2,extract_day,regex_barris,key_open,key_shp))
dim(df_x[df_x$cookd>0.01,])
dim(df_x[df_x$cookd>0.005,])
dim(df_x[df_x$cookd>0.002,])
plot(cooks.distance(lm7))
abline(h = 4*mean(cooksd, na.rm=T), col="red")
# data_cook = data_idealista[-test,]
view(df_x[df_x$cookd>0.005,])
data_cook = df_x[df_x$cookd < 0.005,]
view(data_cook[data_cook$cookd > 0.002,])
data_cook = data_cook[data_cook$cookd < 0.002,]
lm_cook <- lm(log_price ~ 1 + barri + square_mt + asc + rooms2 + wc2 + terraza + exterior + amueblado +
flag_planta + aire + calef
+ lujo
, data = data_cook)
summary(lm_cook)
vif(lm_cook)
plot(lm_cook,ask=FALSE)
coefs <- tidy(lm_cook, conf.int = TRUE)
# Identifica las variables que corresponden a los barrios
coefs$term_group <- ifelse(grepl("^barri", coefs$term), "barri", "other")
# Organiza los términos primero por el grupo (barri u other) y luego alfabéticamente
coefs <- coefs %>%
arrange(term_group, term)
# Elimina la columna term_group ya que ya no la necesitamoshttp://127.0.0.1:41615/graphics/plot_zoom_png?width=1920&height=1027
coefs$term_group <- NULL
# Convierte la variable term en una variable categórica con el orden específico
coefs$term <- factor(coefs$term, levels = coefs$term)
# Crea el gráfico
ggplot(coefs, aes(x = term, y = estimate)) +
geom_point() +
geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(x = "Variables", y = "Estimación", title = "Coeficientes e Intervalos de Confianza del 95%")
summary(lm_cook)
summary(lm_cook)
vif(lm_cook)
coefs
coefs %>% filter(!grepl("^barri",coefs$term))
coefs %>% filter(!grepl("^barri|(Intercept)",coefs$term))
coefs = coefs %>% filter(!grepl("^barri|(Intercept)",coefs$term))
# Elimina la columna term_group ya que ya no la necesitamoshttp://127.0.0.1:41615/graphics/plot_zoom_png?width=1920&height=1027
coefs$term_group <- NULL
# Convierte la variable term en una variable categórica con el orden específico
coefs$term <- factor(coefs$term, levels = coefs$term)
# Crea el gráfico
ggplot(coefs, aes(x = term, y = estimate)) +
geom_point() +
geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(x = "Variables", y = "Estimación", title = "Coeficientes e Intervalos de Confianza del 95%")
lm_cook$model
lm_cook$qr$pivot
source("C:/Users/ggari/Desktop/1_projects/TFM/2_code/2_R_code/3_0_data_modelling.R", encoding = 'UTF-8', echo=TRUE)
model_path = paste0("C:/Users/ggari/Desktop/1_projects/TFM/1_data/2_data_Idealista/model_cook_2023-05-03.RDS")
model_cook = readRDS(model_path)
coefs <- tidy(model_cook, conf.int = TRUE)
# Identifica las variables que corresponden a los barrios
coefs$term_group <- ifelse(grepl("^barri", coefs$term), "barri", "other")
# Organiza los términos primero por el grupo (barri u other) y luego alfabéticamente
coefs <- coefs %>%
arrange(term_group, term)
coefs = coefs %>% filter(!grepl("^barri|(Intercept)",coefs$term))
# Elimina la columna term_group ya que ya no la necesitamoshttp://127.0.0.1:41615/graphics/plot_zoom_png?width=1920&height=1027
coefs$term_group <- NULL
# Convierte la variable term en una variable categórica con el orden específico
coefs$term <- factor(coefs$term, levels = coefs$term)
# Crea el gráfico
ggplot(coefs, aes(x = term, y = estimate)) +
geom_point() +
geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(x = "Variables", y = "Estimación", title = "Coeficientes e Intervalos de Confianza del 95%")
theme_set(theme_minimal())
# Crea el gráfico
ggplot(coefs, aes(x = term, y = estimate)) +
geom_point() +
geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(x = "Variables", y = "Estimación", title = "Coeficientes e Intervalos de Confianza del 95%")
summary(model_cook)
coefs
vif(lm_cook)
tidy(vif(lm_cook))
vif(lm_cook)
tidy(vif(lm_cook))
vif(lm_cook)
as.data.frame(vif(lm_cook))
as.tibble(vif(lm_cook))
as_tibble(vif(lm_cook))
as_tibble_col(vif(lm_cook))
as_tibble_row(vif(lm_cook))
as_tibble(vif(lm_cook))
vif(lm_cook)
as.data.frame(vif(lm_cook))
names(vif(lm_cook))
?as.data.frame
coefs
round(coefs,3)
round(coefs,4)
theme_set(theme_minimal())
data_idealista <- readRDS(here::here('1_data','2_data_Idealista','data_modelling_2023-05-03.RDS'))
colnames(data_idealista)
setwd("C:/Users/ggari/Desktop/1_projects/TFM")
data_idealista <- readRDS(here::here('1_data','2_data_Idealista','data_modelling_2023-05-03.RDS'))
theme_set(theme_minimal())
data_idealista <- readRDS(here::here('1_data','2_data_Idealista','data_modelling_2023-05-03.RDS'))
